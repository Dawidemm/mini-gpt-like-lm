# mini-gpt-like-lm

[![CI](https://github.com/Dawidemm/mini-gpt-like-lm/actions/workflows/ci.yaml/badge.svg)](https://github.com/Dawidemm/mini-gpt-like-lm/actions/workflows/ci.yaml)

## Description

This project aims to build a small-scale language model inspired by GPT-2 architecture and optimized for minimal computational resources and data usage. The goal is to understand the core principles of transformer-based models while exploring strategies to reduce the computational footprint and data requirements typically associated with training large-scale language models.

This project focuses on lightweight model architectures to investigate how to train efficient language models with limited resources while still maintaining strong performance in natural language processing tasks.

## Project Installation

For those interested in a deeper dive into the project, here are the steps to set up the project and get started.

1. **Clone the repository:**

    First, clone the repository to your local machine:

    ```bash
    git clone https://github.com/Dawidemm/mini-gpt-like-lm
    cd mini-gpt-like-lm
    ```

2. **Python Version:**

   This project is developed using Python version **3.11.11**. Please ensure you are using the correct Python version to avoid compatibility issues.

3. **Virtual Environment:**

   It is highly recommended to create a virtual environment to manage dependencies and isolate the project environment.

4. **Install Dependencies:**

   Once the virtual environment is created and activated, install the project dependencies with:

    ```bash
    pip install .
    ```

   This will install all the necessary libraries required to run the project and the project itslef.